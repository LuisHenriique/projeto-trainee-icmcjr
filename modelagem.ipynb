{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "536ddaa8",
   "metadata": {},
   "source": [
    "\n",
    "# Projeto ICMC Júnior\n",
    "## Objetivo: Prever se um funcionário vai sair da empresa (attrition).\n",
    "\n",
    "### Etapa final: Modelagem dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f3f69fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "59d08d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do dataset (usamos, agora, a base limpa gerada na etapa 1 do projeto)\n",
    "df = pd.read_csv('dados_limpos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d555c47",
   "metadata": {},
   "source": [
    "#### Adequação e preparação final dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3038f397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convertendo coluna: 'Attrition'...\n",
      "  Valores ANTES: ['yes' 'no']\n",
      "  Valores DEPOIS: [1 0]\n",
      "\n",
      "Convertendo coluna: 'OverTime'...\n",
      "  Valores ANTES: ['yes' 'no']\n",
      "  Valores DEPOIS: [1 0]\n",
      "\n",
      "Convertendo coluna: 'Gender'...\n",
      "  Valores ANTES: ['female' 'male']\n",
      "  Valores DEPOIS: [1 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Para preparar os dados para a aplicação de um modelo de Machine Learning, devemos garantir que todos os valores sejam numéricos.\n",
    "# Assim, convertemos as colunas qualitativas (categóricas) em quantitativas (numéricas).\n",
    "# Para isso, usamos Label Encoding para colunas binárias e One-Hot Encoding para colunas nominais com mais de duas categorias.\n",
    "\n",
    "# Função para realizar Label Encoding em colunas qualitativas binárias\n",
    "def encoding_binary_columns(column, map_values):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Erro, coluna {column} não encontrada no dataframe\")\n",
    "    \n",
    "    print(f\"Convertendo coluna: '{column}'...\")\n",
    "    print(f\"  Valores ANTES: {df[column].unique()}\")\n",
    "    df[column] = df[column].map(map_values) # Aplica mapeamento na coluna\n",
    "    print(f\"  Valores DEPOIS: {df[column].unique()}\\n\")\n",
    "\n",
    "encoding_binary_columns('Attrition', {'yes': 1, 'no': 0})\n",
    "encoding_binary_columns('OverTime', {'yes': 1, 'no': 0})\n",
    "encoding_binary_columns('Gender', {'female': 1, 'male': 0})\n",
    "\n",
    "# Lista de colunas do tipo qualitativo nominal\n",
    "colunas_nominais = [\n",
    "    'BusinessTravel', \n",
    "    'Department', \n",
    "    'EducationField', \n",
    "    'JobRole', \n",
    "    'MaritalStatus'\n",
    "]\n",
    "# Realiza a conversão do dados de qualitativo para quantitativo (como consequência, teremos um aumento de colunas de 31 para 45).\n",
    "df = pd.get_dummies(df, columns=colunas_nominais, dtype = int, drop_first=True) # 'drop_first=True' evita multicolinearidade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0dbc5962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão das variáveis preditoras (X): (1470, 44)\n",
      "Dimensão da variável alvo (y): (1470,)\n",
      "\n",
      "Tamanho do conjunto de treino: 1102 amostras\n",
      "Tamanho do conjunto de teste: 368 amostras\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Com os dados preparados, é feita uma divisão de treino e teste.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definição da variável alvo (target) e das variáveis preditoras (features)\n",
    "X = df.drop('Attrition', axis=1) # Variáveis preditoras (todas colunas menos 'Attrition')\n",
    "y = df['Attrition'] # Variável alvo\n",
    "print(f\"Dimensão das variáveis preditoras (X): {X.shape}\")\n",
    "print(f\"Dimensão da variável alvo (y): {y.shape}\\n\")\n",
    "\n",
    "# Divisão dos dados em conjuntos de treino e teste (75% treino, 25% teste)\n",
    "# 'random_state=42' garante reprodutibilidade dos resultados; 'stratify=y' mantém a proporção original das classes na divisão\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "print(f\"Tamanho do conjunto de treino: {X_treino.shape[0]} amostras\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_teste.shape[0]} amostras\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c6eb8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Média da primeira coluna de X_treino_padronizado (deve ser ~0): -1.6119390557171058e-17\n",
      "\n",
      "Desvio Padrão da primeira coluna de X_treino_padronizado (deve ser ~1): 1.0\n"
     ]
    }
   ],
   "source": [
    "# Tendo dividido os dados, aplica-se uma padronização sobre os valores (nem todos os modelos de ML exigem isso, mas é uma boa prática).\n",
    "# Nisso, a média de todos os valores se torna 0 e o desvio padrão, 1.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Ajusta o scaler apenas com os dados de treino para evitar vazamento de dados (data leakage)\n",
    "scaler.fit(X_treino)\n",
    "# Aplica a padronização nos conjuntos de treino e teste\n",
    "X_treino_padronizado = scaler.transform(X_treino)\n",
    "X_teste_padronizado = scaler.transform(X_teste)\n",
    "print(f\"\\nMédia da primeira coluna de X_treino_padronizado (deve ser ~0): {X_treino_padronizado[:, 0].mean()}\")\n",
    "print(f\"\\nDesvio Padrão da primeira coluna de X_treino_padronizado (deve ser ~1): {X_treino_padronizado[:, 0].std()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5cbf1f",
   "metadata": {},
   "source": [
    "#### Aplicação dos modelos de Regressão Logísticas e Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad789fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando busca pelos melhores hiperparâmetros (Grid Search) para Random Forest...\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "\n",
      "Melhores parâmetros encontrados: {'C': 10, 'solver': 'liblinear'}\n",
      "Treinando o modelo de Regressão Logística Otimizado...\n",
      "Treinamento concluído!\n",
      "\n",
      "Ajustando o limiar de decisão para: 0.3\n",
      "\n",
      "Avaliação do modelo nos dados de teste---\n",
      "\n",
      "Acurácia (Accuracy): 69.02%\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.67      0.78       309\n",
      "           1       0.32      0.80      0.45        59\n",
      "\n",
      "    accuracy                           0.69       368\n",
      "   macro avg       0.63      0.73      0.62       368\n",
      "weighted avg       0.84      0.69      0.73       368\n",
      "\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[207 102]\n",
      " [ 12  47]]\n"
     ]
    }
   ],
   "source": [
    "# Por fim, com todos os dados preparados e separados devidamente, podemos aplicar o modelo.\n",
    "# Escolhemos a Regressão Logística, resumidamente, por ser um modelo simples, eficiente e interpretável.\n",
    "# Não apenas foi adotado o modelo, mas também foi realizada uma busca em grade (Grid Search) para otimizar seus hiperparâmetros\n",
    "# e personalizou-se o limiar de decisão para melhorar seu desempenho, com foco na métrica recall para '1'.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Cria um objeto do modelo. 'random_state=42' garante reprodutibilidade dos resultados.\n",
    "rl_modelo = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Realiza uma busca em grade (Grid Search)\n",
    "# Essa é uma estratégia que testa várias combinações de parâmetros para otimizar o desempenho do modelo\n",
    "print(\"Iniciando busca pelos melhores hiperparâmetros (Grid Search) para Random Forest...\")\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],  # Testando diferentes forças de regularização\n",
    "    'solver': ['liblinear']          # Solver robusto para datasets menores\n",
    "}\n",
    "# 'scoring' define a métrica usada para avaliar o desempenho durante a busca (aqui, f1-score para que haja equilíbrio entre precisão e recall)\n",
    "# Obs.: apesar de, aqui, ser priorizado o f1-score, a escolha do limiar de decisão posterior visa aumentar o recall, mesmo que isso reduza a precisão\n",
    "grid_search = GridSearchCV(rl_modelo, param_grid, cv=5, scoring='f1', verbose=1)\n",
    "grid_search.fit(X_treino_padronizado, y_treino)\n",
    "\n",
    "# Exibe os melhores parâmetros encontrados pela busca em grade\n",
    "print(f\"\\nMelhores parâmetros encontrados: {grid_search.best_params_}\")\n",
    "# Atualiza o modelo com os melhores parâmetros encontrados\n",
    "rl_modelo = grid_search.best_estimator_\n",
    "\n",
    "# Treina o modelo com os dados de treino padronizados\n",
    "print(\"Treinando o modelo de Regressão Logística Otimizado...\")\n",
    "rl_modelo.fit(X_treino_padronizado, y_treino) # Uso dos dados padronizados de treino\n",
    "print(\"Treinamento concluído!\")\n",
    "\n",
    "# Ajusta limiar de decisão (a chance mínima para classificar como positivo)\n",
    "# O valor padrão é 0.5, mas, após vários treinamentos e avaliações, notou-se que 0.3 oferece um aumento expressivo em 'recall'\n",
    "# apesar do valor menor de 'precision', o que é aceitável nesse contexto (identificar funcionários propensos a deixar a empresa)\n",
    "LIMIAR_RL = 0.3\n",
    "print(f\"\\nAjustando o limiar de decisão para: {LIMIAR_RL}\")\n",
    "\n",
    "print(\"\\nAvaliação do modelo nos dados de teste---\")\n",
    "# Cria previsões usando o modelo treinado aplicando o limiar definido\n",
    "y_prob = rl_modelo.predict_proba(X_teste_padronizado)[:, 1] # Probabilidades da classe positiva (1)\n",
    "y_previsoes = (y_prob >= LIMIAR_RL).astype(int) # Aplica o limiar para obter previsões binárias\n",
    "\n",
    "# Avaliação das previsões (comparar y_previsoes com y_teste)\n",
    "acuracia = accuracy_score(y_teste, y_previsoes)\n",
    "print(f\"\\nAcurácia (Accuracy): {acuracia * 100:.2f}%\")\n",
    "\n",
    "# Relatório de classificação.\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_teste, y_previsoes))\n",
    "\n",
    "# Matriz de confusão.\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(confusion_matrix(y_teste, y_previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "41a6a3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando busca pelos melhores hiperparâmetros (Grid Search) para Random Forest...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melhores parâmetros encontrados: {'max_depth': 5, 'min_samples_leaf': 4, 'n_estimators': 100}\n",
      "Treinando o modelo Random Forest Otimizado...\n",
      "Treinamento concluído!\n",
      "\n",
      "Ajustando o limiar de decisão para: 0.35\n",
      "\n",
      "Avaliação do modelo nos dados de teste---\n",
      "\n",
      "Acurácia (Accuracy): 64.13%\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.60      0.74       309\n",
      "           1       0.29      0.85      0.43        59\n",
      "\n",
      "    accuracy                           0.64       368\n",
      "   macro avg       0.62      0.72      0.58       368\n",
      "weighted avg       0.85      0.64      0.69       368\n",
      "\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[186 123]\n",
      " [  9  50]]\n"
     ]
    }
   ],
   "source": [
    "# Com os dados resultantes da Regressão Logística, é possível tentar um modelo mais complexo: Random Forest.\n",
    "# Assim como na Regressão Logística, aplicamos Grid Search para otimização de hiperparâmetros e ajuste fino do limiar de decisão.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Cria o objeto base do modelo Random Forest.\n",
    "# Mantém class_weight='balanced' para lidar com o desbalanceamento desde o início.\n",
    "rf_base = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Define a grade de parâmetros para o Grid Search.\n",
    "# São testados diferentes números de árvores, profundidades e regras de folhas para controlar overfitting.\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],       # Quantidade de árvores na floresta\n",
    "    'max_depth': [5, 8, 10, None],    # Profundidade máxima de cada árvore\n",
    "    'min_samples_leaf': [1, 2, 4]     # Mínimo de amostras para criar uma folha final\n",
    "}\n",
    "\n",
    "# Configura o Grid Search.\n",
    "# scoring='recall' força o modelo a priorizar a captura da classe minoritária (1).\n",
    "# n_jobs=-1 usa todos os núcleos do processador para acelerar o treinamento.\n",
    "print(\"Iniciando busca pelos melhores hiperparâmetros (Grid Search) para Random Forest...\")\n",
    "grid_search_rf = GridSearchCV(rf_base, param_grid_rf, cv=5, scoring='recall', verbose=1, n_jobs=-1)\n",
    "grid_search_rf.fit(X_treino, y_treino) # Obs.: RF não usa dados padronizados\n",
    "\n",
    "# Exibe e seleciona o melhor modelo encontrado\n",
    "print(f\"\\nMelhores parâmetros encontrados: {grid_search_rf.best_params_}\")\n",
    "rf_modelo_otimizado = grid_search_rf.best_estimator_\n",
    "\n",
    "# Treina o modelo otimizado (redundante, pois o GridSearch já o treinou, mas bom para clareza)\n",
    "print(\"Treinando o modelo Random Forest Otimizado...\")\n",
    "rf_modelo_otimizado.fit(X_treino, y_treino)\n",
    "print(\"Treinamento concluído!\")\n",
    "\n",
    "# Ajuste de limiar de decisão.\n",
    "# Para Random Forest, o padrão também é 0.5. Foi optado um valor de 0.35 para aumentar o recall.\n",
    "LIMIAR_RF = 0.35\n",
    "print(f\"\\nAjustando o limiar de decisão para: {LIMIAR_RF}\")\n",
    "\n",
    "print(\"\\nAvaliação do modelo nos dados de teste---\")\n",
    "# Obtém as probabilidades da classe positiva (1)\n",
    "y_prob_rf = rf_modelo_otimizado.predict_proba(X_teste)[:, 1]\n",
    "# Aplica o limiar personalizado\n",
    "y_previsoes_rf = (y_prob_rf >= LIMIAR_RF).astype(int)\n",
    "\n",
    "# Avaliação das previsões\n",
    "print(f\"\\nAcurácia (Accuracy): {accuracy_score(y_teste, y_previsoes_rf) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_teste, y_previsoes_rf))\n",
    "\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(confusion_matrix(y_teste, y_previsoes_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
