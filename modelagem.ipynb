{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "536ddaa8",
   "metadata": {},
   "source": [
    "\n",
    "# Projeto ICMC Júnior\n",
    "## Objetivo: Prever se um funcionário vai sair da empresa (attrition).\n",
    "\n",
    "### Etapa final: Modelagem dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3f69fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59d08d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do dataset (usamos, agora, a base limpa gerada na etapa 1 do projeto)\n",
    "df = pd.read_csv('dados_limpos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d555c47",
   "metadata": {},
   "source": [
    "#### Adequação e preparação final dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3038f397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convertendo coluna: 'Attrition'...\n",
      "  Valores ANTES: ['yes' 'no']\n",
      "  Valores DEPOIS: [1 0]\n",
      "\n",
      "Convertendo coluna: 'OverTime'...\n",
      "  Valores ANTES: ['yes' 'no']\n",
      "  Valores DEPOIS: [1 0]\n",
      "\n",
      "Convertendo coluna: 'Gender'...\n",
      "  Valores ANTES: ['female' 'male']\n",
      "  Valores DEPOIS: [1 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Para preparar os dados para a aplicação de um modelo de Machine Learning, devemos garantir que todos os valores sejam numéricos.\n",
    "# Assim, convertemos as colunas qualitativas (categóricas) em quantitativas (numéricas).\n",
    "# Para isso, usamos Label Encoding para colunas binárias e One-Hot Encoding para colunas nominais com mais de duas categorias.\n",
    "\n",
    "# Função para realizar Label Encoding em colunas qualitativas binárias\n",
    "def encoding_binary_columns(column, map_values):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Erro, coluna {column} não encontrada no dataframe\")\n",
    "    \n",
    "    print(f\"Convertendo coluna: '{column}'...\")\n",
    "    print(f\"  Valores ANTES: {df[column].unique()}\")\n",
    "    df[column] = df[column].map(map_values) # Aplica mapeamento na coluna\n",
    "    print(f\"  Valores DEPOIS: {df[column].unique()}\\n\")\n",
    "\n",
    "encoding_binary_columns('Attrition', {'yes': 1, 'no': 0})\n",
    "encoding_binary_columns('OverTime', {'yes': 1, 'no': 0})\n",
    "encoding_binary_columns('Gender', {'female': 1, 'male': 0})\n",
    "\n",
    "# Lista de colunas do tipo qualitativo nominal\n",
    "colunas_nominais = [\n",
    "    'BusinessTravel', \n",
    "    'Department', \n",
    "    'EducationField', \n",
    "    'JobRole', \n",
    "    'MaritalStatus'\n",
    "]\n",
    "# Realiza a conversão do dados de qualitativo para quantitativo (como consequência, teremos um aumento de colunas de 31 para 45).\n",
    "df = pd.get_dummies(df, columns=colunas_nominais, dtype = int, drop_first=True) # 'drop_first=True' evita multicolinearidade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dbc5962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão das variáveis preditoras (X): (1470, 44)\n",
      "Dimensão da variável alvo (y): (1470,)\n",
      "\n",
      "Tamanho do conjunto de treino: 1102 amostras\n",
      "Tamanho do conjunto de teste: 368 amostras\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Com os dados preparados, é feita uma divisão de treino e teste.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definição da variável alvo (target) e das variáveis preditoras (features)\n",
    "X = df.drop('Attrition', axis=1) # Variáveis preditoras (todas colunas menos 'Attrition')\n",
    "y = df['Attrition'] # Variável alvo\n",
    "print(f\"Dimensão das variáveis preditoras (X): {X.shape}\")\n",
    "print(f\"Dimensão da variável alvo (y): {y.shape}\\n\")\n",
    "\n",
    "# Divisão dos dados em conjuntos de treino e teste (75% treino, 25% teste)\n",
    "# 'random_state=42' garante reprodutibilidade dos resultados; 'stratify=y' mantém a proporção original das classes na divisão\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "print(f\"Tamanho do conjunto de treino: {X_treino.shape[0]} amostras\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_teste.shape[0]} amostras\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c6eb8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Média da primeira coluna de X_treino_padronizado (deve ser ~0): -1.6119390557171058e-17\n",
      "\n",
      "Desvio Padrão da primeira coluna de X_treino_padronizado (deve ser ~1): 1.0\n"
     ]
    }
   ],
   "source": [
    "# Tendo dividido os dados, aplica-se uma padronização sobre os valores (nem todos os modelos de ML exigem isso, mas é uma boa prática).\n",
    "# Nisso, a média de todos os valores se torna 0 e o desvio padrão, 1.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Ajusta o scaler apenas com os dados de treino para evitar vazamento de dados (data leakage)\n",
    "scaler.fit(X_treino)\n",
    "# Aplica a padronização nos conjuntos de treino e teste\n",
    "X_treino_padronizado = scaler.transform(X_treino)\n",
    "X_teste_padronizado = scaler.transform(X_teste)\n",
    "print(f\"\\nMédia da primeira coluna de X_treino_padronizado (deve ser ~0): {X_treino_padronizado[:, 0].mean()}\")\n",
    "print(f\"\\nDesvio Padrão da primeira coluna de X_treino_padronizado (deve ser ~1): {X_treino_padronizado[:, 0].std()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5cbf1f",
   "metadata": {},
   "source": [
    "#### Aplicação do modelo de Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad789fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando o modelo de Regressão Logística...\n",
      "Treinamento concluído!\n",
      "\n",
      "Avaliação do modelo nos dados de teste---\n",
      "\n",
      "Acurácia (Accuracy): 78.53%\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86       309\n",
      "           1       0.40      0.64      0.49        59\n",
      "\n",
      "    accuracy                           0.79       368\n",
      "   macro avg       0.66      0.73      0.68       368\n",
      "weighted avg       0.84      0.79      0.80       368\n",
      "\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[251  58]\n",
      " [ 21  38]]\n"
     ]
    }
   ],
   "source": [
    "# Por fim, com todos os dados preparados e separados devidamente, podemos aplicar o modelo.\n",
    "# Escolhemos a Regressão Logística, resumidamente, por ser um modelo simples, eficiente e interpretável.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Cria um objeto do modelo. 'random_state=42' garante reprodutibilidade dos resultados.\n",
    "modelo = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "\n",
    "print(\"Treinando o modelo de Regressão Logística...\")\n",
    "modelo.fit(X_treino_padronizado, y_treino) # Uso dos dados padronizados de treino\n",
    "print(\"Treinamento concluído!\")\n",
    "\n",
    "print(\"\\nAvaliação do modelo nos dados de teste---\")\n",
    "# Cria previsões usando o modelo treinado\n",
    "y_previsoes = modelo.predict(X_teste_padronizado) # Uso dos dados padronizados de teste\n",
    "\n",
    "# Avaliação das previsões (comparar y_previsoes com y_teste)\n",
    "acuracia = accuracy_score(y_teste, y_previsoes)\n",
    "print(f\"\\nAcurácia (Accuracy): {acuracia * 100:.2f}%\")\n",
    "\n",
    "# Relatório de classificação.\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_teste, y_previsoes))\n",
    "\n",
    "# Matriz de confusão.\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(confusion_matrix(y_teste, y_previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a6a3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando o modelo Random Forest...\n",
      "Treinamento concluído!\n",
      "\n",
      "Avaliação do modelo nos dados de teste---\n",
      "\n",
      "Acurácia (Accuracy): 82.88%\n",
      "\n",
      "Relatório de Classificação (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.90       309\n",
      "           1       0.41      0.15      0.22        59\n",
      "\n",
      "    accuracy                           0.83       368\n",
      "   macro avg       0.63      0.56      0.56       368\n",
      "weighted avg       0.78      0.83      0.79       368\n",
      "\n",
      "\n",
      "Matriz de Confusão (Random Forest):\n",
      "[[296  13]\n",
      " [ 50   9]]\n"
     ]
    }
   ],
   "source": [
    "# Com os dados resultantes da Regressão Logística, é possível tentar um modelo mais complexo, como o Random Forest.\n",
    "# O código segue a mesma lógica do trecho que usa Regressão Logística, mas aplicando o modelo Random Forest.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Cria um objeto do modelo Random Forest.\n",
    "rf_modelo = RandomForestClassifier(\n",
    "    n_estimators=100,        # Número de árvores na floresta\n",
    "    random_state=42,         # Para reprodutibilidade\n",
    "    class_weight='balanced',  # Foca na classe 1 (foca em prever \"yes\" corretamente)\n",
    "    max_depth=8              # Limita a profundidade das árvores para evitar overfitting\n",
    ")\n",
    "\n",
    "print(\"Treinando o modelo Random Forest...\")\n",
    "rf_modelo.fit(X_treino, y_treino) # Obs.: para este modelo, não usamos os dados padronizados\n",
    "print(\"Treinamento concluído!\")\n",
    "\n",
    "print(\"\\nAvaliação do modelo nos dados de teste---\")\n",
    "y_previsoes_rf = rf_modelo.predict(X_teste) # Novamente, não usamos dados padronizados\n",
    "\n",
    "print(f\"\\nAcurácia (Accuracy): {accuracy_score(y_teste, y_previsoes_rf) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nRelatório de Classificação (Random Forest):\")\n",
    "print(classification_report(y_teste, y_previsoes_rf))\n",
    "\n",
    "print(\"\\nMatriz de Confusão (Random Forest):\")\n",
    "print(confusion_matrix(y_teste, y_previsoes_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
